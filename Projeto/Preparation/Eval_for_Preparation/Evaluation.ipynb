{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ndarray\n",
    "from pandas import DataFrame, read_csv\n",
    "from matplotlib.pyplot import savefig, show, figure\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_NB(trnX, trnY, tstX, tstY, metric: str = \"accuracy\") -> dict[str, float]:\n",
    "    estimators: dict[str, GaussianNB | MultinomialNB | BernoulliNB] = {\n",
    "        \"GaussianNB\": GaussianNB(),\n",
    "        \"MultinomialNB\": MultinomialNB(),\n",
    "        \"BernoulliNB\": BernoulliNB(),\n",
    "    }\n",
    "    best_model: GaussianNB | MultinomialNB | BernoulliNB = None  # type: ignore\n",
    "    best_performance: float = 0.0\n",
    "    eval: dict[str, float] = {}\n",
    "\n",
    "    for clf in estimators:\n",
    "        estimators[clf].fit(trnX, trnY)\n",
    "        prdY: ndarray = estimators[clf].predict(tstX)\n",
    "        performance: float = CLASS_EVAL_METRICS[metric](tstY, prdY)\n",
    "        if performance - best_performance > DELTA_IMPROVE:\n",
    "            best_performance = performance\n",
    "            best_model = estimators[clf]\n",
    "    if best_model is not None:\n",
    "        prd: ndarray = best_model.predict(tstX)\n",
    "        for key in CLASS_EVAL_METRICS:\n",
    "            eval[key] = CLASS_EVAL_METRICS[key](tstY, prd)\n",
    "    return eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_KNN(trnX, trnY, tstX, tstY, metric=\"accuracy\") -> dict[str, float]:\n",
    "    kvalues: list[int] = [1] + [i for i in range(5, 26, 5)]\n",
    "    best_model: KNeighborsClassifier = None  # type: ignore\n",
    "    best_performance: float = 0\n",
    "    eval: dict[str, float] = {}\n",
    "    for k in kvalues:\n",
    "        clf = KNeighborsClassifier(n_neighbors=k, metric=\"euclidean\")\n",
    "        clf.fit(trnX, trnY)\n",
    "        prdY: ndarray = clf.predict(tstX)\n",
    "        performance: float = CLASS_EVAL_METRICS[metric](tstY, prdY)\n",
    "        if performance - best_performance > DELTA_IMPROVE:\n",
    "            best_performance = performance\n",
    "            best_model: KNeighborsClassifier = clf\n",
    "    if best_model is not None:\n",
    "        prd: ndarray = best_model.predict(tstX)\n",
    "        for key in CLASS_EVAL_METRICS:\n",
    "            eval[key] = CLASS_EVAL_METRICS[key](tstY, prd)\n",
    "    return eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.axes import Axes\n",
    "\n",
    "\n",
    "def plot_multibar_chart(\n",
    "    group_labels: list,\n",
    "    yvalues: dict,\n",
    "    ax: Axes = None,  # type: ignore\n",
    "    title: str = \"\",\n",
    "    xlabel: str = \"\",\n",
    "    ylabel: str = \"\",\n",
    "    percentage: bool = False,\n",
    ") -> Axes | list[Axes]:\n",
    "    if ax is None:\n",
    "        ax = gca()\n",
    "    ax = set_chart_labels(ax=ax, title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    if percentage:\n",
    "        ax.set_ylim(0.0, 1.0)\n",
    "    bar_labels: list = list(yvalues.keys())\n",
    "\n",
    "    # This is the location for each bar\n",
    "    index: ndarray = arange(len(group_labels))\n",
    "    bar_width: float = 0.8 / len(bar_labels)\n",
    "    ax.set_xticks(index + bar_width / 2, labels=group_labels)\n",
    "\n",
    "    for i in range(len(bar_labels)):\n",
    "        bar_yvalues = yvalues[bar_labels[i]]\n",
    "        values: BarContainer = ax.bar(\n",
    "            index + i * bar_width,\n",
    "            bar_yvalues,\n",
    "            width=bar_width,\n",
    "            label=bar_labels[i],\n",
    "        )\n",
    "        format = \"%.2f\" if percentage else \"%.0f\"\n",
    "        ax.bar_label(values, fmt=format, fontproperties=FONT_TEXT)\n",
    "        if any(y < 0 for y in bar_yvalues) and percentage:\n",
    "            ax.set_ylim(-1.0, 1.0)\n",
    "    ax.legend(fontsize=\"xx-small\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_approach(\n",
    "    train: DataFrame, test: DataFrame, target: str = \"class\", metric: str = \"accuracy\"\n",
    ") -> dict[str, list]:\n",
    "    trnY = train.pop(target).values\n",
    "    trnX: ndarray = train.values\n",
    "    tstY = test.pop(target).values\n",
    "    tstX: ndarray = test.values\n",
    "    eval: dict[str, list] = {}\n",
    "\n",
    "    eval_NB: dict[str, float] = run_NB(trnX, trnY, tstX, tstY, metric=metric)\n",
    "    eval_KNN: dict[str, float] = run_KNN(trnX, trnY, tstX, tstY, metric=metric)\n",
    "    if eval_NB != {} and eval_KNN != {}:\n",
    "        for met in CLASS_EVAL_METRICS:\n",
    "            eval[met] = [eval_NB[met], eval_KNN[met]]\n",
    "    return eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m test[:] \u001b[38;5;241m=\u001b[39m imputer\u001b[38;5;241m.\u001b[39mtransform(test)\n\u001b[1;32m     31\u001b[0m figure()\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28meval\u001b[39m: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m] \u001b[38;5;241m=\u001b[39m evaluate_approach(train, test, target\u001b[38;5;241m=\u001b[39mtarget, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m plot_multibar_chart(\n\u001b[1;32m     34\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNB\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKNN\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28meval\u001b[39m, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_tag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m, percentage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     36\u001b[0m savefig(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_tag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_eval.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m, in \u001b[0;36mevaluate_approach\u001b[0;34m(train, test, target, metric)\u001b[0m\n\u001b[1;32m      7\u001b[0m tstX: ndarray \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28meval\u001b[39m: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 10\u001b[0m eval_NB: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m run_NB(trnX, trnY, tstX, tstY, metric\u001b[38;5;241m=\u001b[39mmetric)\n\u001b[1;32m     11\u001b[0m eval_KNN: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m run_KNN(trnX, trnY, tstX, tstY, metric\u001b[38;5;241m=\u001b[39mmetric)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_NB \u001b[38;5;241m!=\u001b[39m {} \u001b[38;5;129;01mand\u001b[39;00m eval_KNN \u001b[38;5;241m!=\u001b[39m {}:\n",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m, in \u001b[0;36mrun_NB\u001b[0;34m(trnX, trnY, tstX, tstY, metric)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28meval\u001b[39m: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m clf \u001b[38;5;129;01min\u001b[39;00m estimators:\n\u001b[0;32m---> 12\u001b[0m     estimators[clf]\u001b[38;5;241m.\u001b[39mfit(trnX, trnY)\n\u001b[1;32m     13\u001b[0m     prdY: ndarray \u001b[38;5;241m=\u001b[39m estimators[clf]\u001b[38;5;241m.\u001b[39mpredict(tstX)\n\u001b[1;32m     14\u001b[0m     performance: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m CLASS_EVAL_METRICS[metric](tstY, prdY)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/naive_bayes.py:759\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    757\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_counters(n_classes, n_features)\n\u001b[0;32m--> 759\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count(X, Y)\n\u001b[1;32m    760\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_alpha()\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_feature_log_prob(alpha)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/naive_bayes.py:881\u001b[0m, in \u001b[0;36mMultinomialNB._count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_count\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[1;32m    880\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 881\u001b[0m     check_non_negative(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultinomialNB (input X)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    882\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m safe_sparse_dot(Y\u001b[38;5;241m.\u001b[39mT, X)\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1689\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[0;34m(X, whom)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mmin(X)\n\u001b[1;32m   1688\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1689\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m whom)\n",
      "\u001b[0;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "CLASS_EVAL_METRICS = {\n",
    "    \"accuracy\": accuracy_score,\n",
    "    \"recall\": recall_score,\n",
    "    \"precision\": precision_score,\n",
    "    \"f1\": f1_score,\n",
    "}\n",
    "\n",
    "DELTA_IMPROVE = 0.01\n",
    "\n",
    "target = \"LAW_CAT_CD\"\n",
    "file_tag = \"arrest\"\n",
    "train: DataFrame = read_csv(\"/Users/dominikfrank/Desktop/University/Master/Semester 1/PII/Data Science/Code for Project/DataScience/Projeto/Preparation/new_class_ny_arrests.csv\")\n",
    "test: DataFrame = read_csv(\"/Users/dominikfrank/Desktop/University/Master/Semester 1/PII/Data Science/Code for Project/DataScience/Projeto/Preparation/Ny_Arrest_drop_outliers.csv\")\n",
    "\n",
    "# Drop the 'Unnamed: 0' column if it exists\n",
    "train = train.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "test = test.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "\n",
    "if target not in train.columns or target not in test.columns:\n",
    "    raise KeyError(f\"Column '{target}' not found in train or test DataFrame\")\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "train[:] = imputer.fit_transform(train)\n",
    "test[:] = imputer.transform(test)\n",
    "\n",
    "figure()\n",
    "eval: dict[str, list] = evaluate_approach(train, test, target=target, metric=\"recall\")\n",
    "plot_multibar_chart(\n",
    "    [\"NB\", \"KNN\"], eval, title=f\"{file_tag} evaluation\", percentage=True\n",
    ")\n",
    "savefig(f\"images/{file_tag}_eval.png\")\n",
    "show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
